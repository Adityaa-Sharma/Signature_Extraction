{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mType:\u001b[0m        module\n",
      "\u001b[1;31mString form:\u001b[0m <module 'pytesseract' from 'c:\\\\Users\\\\91978\\\\anaconda3\\\\lib\\\\site-packages\\\\pytesseract\\\\__init__.py'>\n",
      "\u001b[1;31mFile:\u001b[0m        c:\\users\\91978\\anaconda3\\lib\\site-packages\\pytesseract\\__init__.py\n",
      "\u001b[1;31mSource:\u001b[0m     \n",
      "\u001b[1;31m# flake8: noqa: F401\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpytesseract\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mALTONotSupported\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpytesseract\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_languages\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpytesseract\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_tesseract_version\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpytesseract\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage_to_alto_xml\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpytesseract\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage_to_boxes\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpytesseract\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage_to_data\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpytesseract\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage_to_osd\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpytesseract\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage_to_pdf_or_hocr\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpytesseract\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage_to_string\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpytesseract\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOutput\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpytesseract\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrun_and_get_multiple_output\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpytesseract\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpytesseract\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTesseractError\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpytesseract\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTesseractNotFoundError\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpytesseract\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTSVNotSupported\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[0m__version__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'0.3.13'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "pytesseract??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      "  \n",
      "\n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "\n",
    "# Configure Tesseract executable path (update it based on your system)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary = cv2.threshold(grayscale, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    return image, grayscale, binary\n",
    "\n",
    "# Function to extract text using Tesseract OCR\n",
    "def extract_text(grayscale):\n",
    "    custom_config = r'--oem 3 --psm 6'\n",
    "    text = pytesseract.image_to_string(grayscale, config=custom_config)\n",
    "    return text\n",
    "\n",
    "# Function to detect and extract non-text elements (e.g., signatures, seals)\n",
    "def extract_non_text_elements(binary, original_image):\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    signature_contours = []\n",
    "    seal_contours = []\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        aspect_ratio = w / float(h)\n",
    "\n",
    "        # Heuristic to classify signature and seal\n",
    "        if 2.5 < aspect_ratio < 8.0 and w > 50 and h < 50:  # Likely a signature\n",
    "            signature_contours.append((x, y, w, h))\n",
    "        elif 0.8 < aspect_ratio < 1.2 and 50 < w < 200:  # Likely a seal\n",
    "            seal_contours.append((x, y, w, h))\n",
    "\n",
    "    # Extract and save detected elements with increased size\n",
    "    padding = 10  # Increase the size by adding padding\n",
    "    signatures = [original_image[max(0, y-padding):y+h+padding, max(0, x-padding):x+w+padding] for x, y, w, h in signature_contours]\n",
    "    seals = [original_image[max(0, y-padding):y+h+padding, max(0, x-padding):x+w+padding] for x, y, w, h in seal_contours]\n",
    "\n",
    "    return signatures, seals\n",
    "\n",
    "# Function to save extracted elements\n",
    "def save_elements(elements, prefix):\n",
    "    for i, element in enumerate(elements):\n",
    "        filename = f\"{prefix}_{i+1}.png\"\n",
    "        cv2.imwrite(filename, element)\n",
    "        print(f\"Saved {prefix}: {filename}\")\n",
    "\n",
    "# Main function to process the image\n",
    "def process_image(image_path):\n",
    "    image, grayscale, binary = preprocess_image(image_path)\n",
    "\n",
    "    # Extract and print text\n",
    "    text = extract_text(grayscale)\n",
    "    print(\"Extracted Text:\\n\", text)\n",
    "\n",
    "    # Extract signatures and seals\n",
    "    signatures, seals = extract_non_text_elements(binary, image)\n",
    "\n",
    "    # Save results\n",
    "    save_elements(signatures, \"signature\")\n",
    "    save_elements(seals, \"seal\")\n",
    "\n",
    "# Input image path\n",
    "image_path = \"New folder/test6.png\"\n",
    "process_image(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned image with signatures and seals: cleaned_image_with_signatures_seals.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "\n",
    "# Configure Tesseract executable path (update it based on your system)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary = cv2.threshold(grayscale, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    return image, grayscale, binary\n",
    "\n",
    "# Function to remove text from the image\n",
    "def remove_text(grayscale, original_image):\n",
    "    custom_config = r'--oem 3 --psm 6'\n",
    "    h, w = grayscale.shape\n",
    "\n",
    "    # Extract bounding boxes of text detected by Tesseract\n",
    "    boxes = pytesseract.image_to_boxes(grayscale, config=custom_config)\n",
    "    for box in boxes.splitlines():\n",
    "        b = box.split()\n",
    "        x, y, x2, y2 = int(b[1]), int(b[2]), int(b[3]), int(b[4])\n",
    "        x, y, x2, y2 = max(0, x), h - max(0, y2), min(w, x2), h - min(h, y)\n",
    "        cv2.rectangle(original_image, (x, y), (x2, y2), (255, 255, 255), -1)\n",
    "\n",
    "    return original_image\n",
    "\n",
    "# Function to detect and extract non-text elements (e.g., signatures, seals)\n",
    "def extract_non_text_elements(binary, original_image):\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    non_text_mask = np.zeros_like(original_image, dtype=np.uint8)\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        aspect_ratio = w / float(h)\n",
    "\n",
    "        # Heuristic to classify signature and seal\n",
    "        if (2.5 < aspect_ratio < 8.0 and w > 50 and h < 50) or (0.8 < aspect_ratio < 1.2 and 50 < w < 200):\n",
    "            # Likely a signature or seal\n",
    "            cv2.drawContours(non_text_mask, [contour], -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "\n",
    "    return non_text_mask\n",
    "\n",
    "# Function to overlay non-text elements on a blank canvas\n",
    "def overlay_non_text_elements(original_image, non_text_mask):\n",
    "    result = np.full_like(original_image, 255)  # Create a white canvas\n",
    "    result[non_text_mask == 255] = original_image[non_text_mask == 255]\n",
    "    return result\n",
    "\n",
    "# Main function to process the image\n",
    "def process_image(image_path):\n",
    "    image, grayscale, binary = preprocess_image(image_path)\n",
    "\n",
    "    # Remove text from the image\n",
    "    image_without_text = remove_text(grayscale, image.copy())\n",
    "\n",
    "    # Extract non-text elements (signatures and seals)\n",
    "    non_text_mask = extract_non_text_elements(binary, image)\n",
    "\n",
    "    # Combine the signatures and seals with the blank canvas\n",
    "    final_image = overlay_non_text_elements(image_without_text, non_text_mask)\n",
    "\n",
    "    # Save the final image\n",
    "    cv2.imwrite(\"cleaned_image_with_signatures_seals.png\", final_image)\n",
    "    print(\"Saved cleaned image with signatures and seals: cleaned_image_with_signatures_seals.png\")\n",
    "\n",
    "# Input image path\n",
    "image_path = \"New folder/test5.png\"\n",
    "process_image(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned image with signatures and seals: cleaned_image_with_signatures_seals.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "\n",
    "# Configure Tesseract executable path (update it based on your system)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary = cv2.threshold(grayscale, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    return image, grayscale, binary\n",
    "\n",
    "# Function to remove text from the image\n",
    "def remove_text(grayscale, original_image):\n",
    "    custom_config = r'--oem 3 --psm 6'\n",
    "    h, w = grayscale.shape\n",
    "\n",
    "    # Extract bounding boxes of text detected by Tesseract\n",
    "    boxes = pytesseract.image_to_boxes(grayscale, config=custom_config)\n",
    "    for box in boxes.splitlines():\n",
    "        b = box.split()\n",
    "        x, y, x2, y2 = int(b[1]), int(b[2]), int(b[3]), int(b[4])\n",
    "        x, y, x2, y2 = max(0, x), h - max(0, y2), min(w, x2), h - min(h, y)\n",
    "        cv2.rectangle(original_image, (x, y), (x2, y2), (255, 255, 255), -1)\n",
    "\n",
    "    return original_image\n",
    "\n",
    "# Function to detect and extract non-text elements (e.g., signatures, seals)\n",
    "def extract_non_text_elements(binary, original_image):\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    non_text_mask = np.zeros_like(original_image, dtype=np.uint8)\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        aspect_ratio = w / float(h)\n",
    "\n",
    "        # Heuristic to classify signature and seal\n",
    "        if (2.5 < aspect_ratio < 8.0 and w > 50 and h < 50) or (0.8 < aspect_ratio < 1.2 and 50 < w < 200):\n",
    "            # Likely a signature or seal\n",
    "            cv2.drawContours(non_text_mask, [contour], -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "\n",
    "    return non_text_mask\n",
    "\n",
    "# Function to overlay non-text elements on a blank canvas\n",
    "def overlay_non_text_elements(original_image, non_text_mask):\n",
    "    result = np.full_like(original_image, 255)  # Create a white canvas\n",
    "    result[non_text_mask == 255] = original_image[non_text_mask == 255]\n",
    "    return result\n",
    "\n",
    "# Main function to process the image\n",
    "def process_image(image_path):\n",
    "    image, grayscale, binary = preprocess_image(image_path)\n",
    "\n",
    "    # Remove text from the image\n",
    "    image_without_text = remove_text(grayscale, image.copy())\n",
    "\n",
    "    # Extract non-text elements (signatures and seals)\n",
    "    non_text_mask = extract_non_text_elements(binary, image)\n",
    "\n",
    "    # Combine the signatures and seals with the blank canvas\n",
    "    final_image = overlay_non_text_elements(image_without_text, non_text_mask)\n",
    "\n",
    "    # Save the final image\n",
    "    cv2.imwrite(\"cleaned_image_with_signatures_seals.png\", final_image)\n",
    "    print(\"Saved cleaned image with signatures and seals: cleaned_image_with_signatures_seals.png\")\n",
    "\n",
    "# Input image path\n",
    "image_path = \"New folder/test5.png\"\n",
    "process_image(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignatureAndSeal:\n",
    "    def __init__(self, image_path):\n",
    "        self.image_path = image_path\n",
    "        self.image = cv2.imread(image_path)\n",
    "        self.grayscale = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n",
    "        self.binary = cv2.threshold(self.grayscale, 150, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "    def extract_text(self):\n",
    "        custom_config = r'--oem 3 --psm 6'\n",
    "        self.text = pytesseract.image_to_string(self.grayscale, config=custom_config)\n",
    "        return self.text\n",
    "\n",
    "    def extract_non_text_elements(self):\n",
    "        contours, _ = cv2.findContours(self.binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        self.signature_contours = []\n",
    "        self.seal_contours = []\n",
    "\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            aspect_ratio = w / float(h)\n",
    "\n",
    "            # Heuristic to classify signature and seal\n",
    "            if 2.5 < aspect_ratio < 8.0 and w > 50 and h < 50:  # Likely a signature\n",
    "                self.signature_contours.append((x, y, w, h))\n",
    "            elif 0.8 < aspect_ratio < 1.2 and 50 < w < 200:  # Likely a seal\n",
    "                self.seal_contours.append((x, y, w, h))\n",
    "\n",
    "        # Extract and save detected elements with increased size\n",
    "        padding = 10  # Increase the size by adding padding\n",
    "        self.signatures = [self.image[max(0, y-padding):y+h+padding, max(0, x-padding):x+w+padding] for x, y, w, h in self.signature_contours]\n",
    "        self.seals = [self.image[max(0, y-padding):y+h+padding, max(0, x-padding):x+w+padding] for x, y, w, h in self.seal_contours]\n",
    "\n",
    "    def save_elements(self):\n",
    "        for i, signature in enumerate(self.signatures):\n",
    "            filename = f\"signature_{i+1}.png\"\n",
    "            cv2.imwrite(filename, signature)\n",
    "            print(f\"Saved signature: {filename}\")\n",
    "\n",
    "        for i, seal in enumerate(self.seals):\n",
    "            filename = f\"seal_{i+1}.png\"\n",
    "            cv2.imwrite(filename, seal)\n",
    "            \n",
    "            print(f\"Saved seal: {filename}\")\n",
    "            \n",
    "            \n",
    "# Input image path\n",
    "image_path = \"New folder/test6.png\"\n",
    "signature_and_seal = SignatureAndSeal(image_path)\n",
    "signature_and_seal.extract_text()\n",
    "signature_and_seal.extract_non_text_elements()\n",
    "signature_and_seal.save_elements()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved extracted signatures and seals to output\\extracted_signatures_sealstest.png.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Preprocess the image for better signature and seal detection.\n",
    "    \"\"\"\n",
    "    # Read the image\n",
    "    img = cv2.imread(str(image_path))\n",
    "    if img is None:\n",
    "        raise ValueError(\"Could not read the image\")\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "        cv2.THRESH_BINARY_INV, 11, 2\n",
    "    )\n",
    "    \n",
    "    return img, thresh\n",
    "\n",
    "def detect_signature_seal(thresh_img):\n",
    "    \"\"\"\n",
    "    Detect potential signature and seal regions using contour analysis.\n",
    "    \"\"\"\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(\n",
    "        thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "    \n",
    "    # Filter contours based on area and aspect ratio\n",
    "    signature_seal_regions = []\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        aspect_ratio = w / h if h != 0 else 0\n",
    "        \n",
    "        # Adjust these thresholds based on your specific needs\n",
    "        if area > 500 and 0.2 < aspect_ratio < 5:\n",
    "            signature_seal_regions.append((x, y, w, h))\n",
    "    \n",
    "    return signature_seal_regions\n",
    "\n",
    "def extract_regions(img, regions, padding=10):\n",
    "    \"\"\"\n",
    "    Extract the identified regions with padding and create a mask.\n",
    "    \"\"\"\n",
    "    mask = np.zeros_like(img)\n",
    "    \n",
    "    for x, y, w, h in regions:\n",
    "        # Add padding to the region\n",
    "        x1 = max(0, x - padding)\n",
    "        y1 = max(0, y - padding)\n",
    "        x2 = min(img.shape[1], x + w + padding)\n",
    "        y2 = min(img.shape[0], y + h + padding)\n",
    "        \n",
    "        # Add region to mask\n",
    "        mask[y1:y2, x1:x2] = img[y1:y2, x1:x2]\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def main(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Main function to process the image and save the result.\n",
    "    \"\"\"\n",
    "    # Convert paths to Path objects\n",
    "    input_path = Path(input_path)\n",
    "    output_path = Path(output_path)\n",
    "    \n",
    "    try:\n",
    "        # Process image\n",
    "        original_img, thresh_img = preprocess_image(input_path)\n",
    "        \n",
    "        # Detect signature and seal regions\n",
    "        regions = detect_signature_seal(thresh_img)\n",
    "        \n",
    "        # Extract regions\n",
    "        result = extract_regions(original_img, regions)\n",
    "        \n",
    "        # Save result\n",
    "        cv2.imwrite(str(output_path), result)\n",
    "        print(f\"Successfully saved extracted signatures and seals to {output_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {str(e)}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_path = \"New folder/test.png\"  # Replace with your input image path\n",
    "    output_path = f\"output/extracted_signatures_seals{input_path[11:]}.jpg\"  # Replace with desired output path\n",
    "    main(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
